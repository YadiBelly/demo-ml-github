{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YadiBelly/demo-ml-github/blob/main/Yadisa's_01_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnUQs11DflMR"
      },
      "source": [
        "# A quickstart introduction\n",
        "\n",
        "## An example ...\n",
        "As part of a [conservation effort](http://burrowingowlconservation.org/sightings/), Ann would like to report sightings of Burrowing Owls as she is hiking. Unfortunately, Ann doesn't know what a Burrowing Owl looks like so she goes to the web to look at pictures. What she has then, is a set of images that are labeled. By examining these labeled images she is **training** herself to recognize Burrowing Owls. \n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/owls2.png)\n",
        "\n",
        "\n",
        "More generally, we can call this set of labeled images used for training, the **labeled training dataset**. Let's dive into this idea of a labeled training dataset a bit more. Suppose Clara is given the task of distinguishing between pictures of telecaster style guitars and stratocaster. But not to worry, because her boss has given her thousands of pictures of guitars. When looking at a picture, the only thing Clara knows is that it is of either a stratocaster or a telecaster. For example, here are some pictures of stratocasters and telecasters. \n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/guitars2.png)\n",
        "\n",
        "\n",
        "Again, when looking at a picture all she knows is that it is a picture of a stratocaster or telecaster but she doesn't know which of the two it is. How long will it take for Clara to learn how to distinguish between these two guitar styles? Would the time be significantly shorter if her boss gave her 10,000 pictures or 100,000? If this is all the information she gets, she will never learn. What she needs is a **labeled** dataset. When presented with a picture she needs to know whether it is a picture of a stratocaster or a telecaster. \n",
        "\n",
        "\n",
        "**Now back to Ann learning to recognize Burrowing Owls**\n",
        "\n",
        "When Ann is learning to recognize Burrowing Owls from her labeled training set, she is developing a model of what features make it a Burrowing Owl. Once she is done learning she can be on a hike, see an animal, and classify it as a Burrowing Owl or something else. This is an **inference** process---based on the evidence of different features of the animal she can infer what it is. And to throw more jargon at you, this type of problem is called a **classification problem**. In classification problems the system is given the features of an object and it needs to classify that object. For example,\n",
        "\n",
        "* The features might be the words of a Twitter post (i.e., *Everything Everywhere All At Once was a f-ing masterpiece. I can't emphasize how great this movie is, it's just that great.*) and based on those features the system classifies the post as positve, negative, or neutral.\n",
        "* The features might be the pixels of an image and based on those pixels the system classifies the image into one of 1,000 categories (it's an image of an owl, a bicycle).\n",
        "\n",
        "\n",
        "\n",
        "## machine learning\n",
        "In machine learning, classification systems have a similar two step process. First is the training phase where the system uses a labeled training dataset to build a model. (We will learn about the architecture of these models and how they learn a bit later.) \n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/quickDiagram2.png)\n",
        "\n",
        "\n",
        "\n",
        "> **Supervised vs. Unsupervised learning**. When a machine learning system trains on labeled data this is called supervised learning. When a system learns with unlabeled data this is called unsupervised learning. A very common example of unsupervised learning is clustering where we might give our system a million unlabeled pictures and ask it to divide the images into 10 groups. \n",
        "\n",
        "Once we have a trained model, we can use that model for inference---we can give it pictures and the system can classify them as burrowing owl or something else. Again, the two phases are:\n",
        "\n",
        "1. training\n",
        "2. inference\n",
        "\n",
        "In this introduction we are going to ignore the training phase and learn a bit about inference. To do that we are going to use a pre-trained model. What *pre-trained model* simply means is that someone else designed the architecture of the model and trained it. \n",
        "\n",
        "### AlexNet\n",
        "\n",
        "The pretrained model we will use is AlexNet. AlexNet was designed by Alex Krishevsky, Ilya Sutskever, and Geoffrey Hinton. In 2012, AlexNet won a competition where the competing systems had to classify images into one of 1,000 categories. AlexNet had a 15% error rate and the error rate of the second place winner was over 25%. Since then there are dozens of systems that perform better, but we will use AlexNet because of its historic significance. The pretrained AlexNet was trained on a labeled training dataset of over one million images.\n",
        "\n",
        "## Let's get started\n",
        "\n",
        "#### First, a note ...\n",
        "The intent of this notebook is for you to learn a little bit about data mining and have a bit of fun. The idea is not for you to understand every line of code. That will come later.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "**First let's set the runtime to GPU (Graphics Processing Unit) -- click on 'runtime' in the menu above, select 'Change runtime type' and pick 'GPU'.**\n",
        "\n",
        "Let's check to see if we set the runtime to GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xh0M2g6Tl6C"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXl7t6HpT2jk"
      },
      "source": [
        "You should see something like:\n",
        "\n",
        "```\n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   64C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```\n",
        "\n",
        "Showing, for example, that we are using a Tesla T4 GPU\n",
        "\n",
        "Now we will set up a variable to allow us to use the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4NoR3PrrVdBD",
        "outputId": "48e1911f-2c57-4ab0-edcc-a27c81a321f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\"  \n",
        "device = torch.device(dev) \n",
        "dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbSyRnWYflMY"
      },
      "source": [
        "### 1. Install Pytorch Lightning.\n",
        "First, let's install the Pytorch Lightning library on our virtual machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm_bhhMjflMY",
        "outputId": "faf1bcf3-eabe-4d27-bbd0-625956918011",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.9.3-py3-none-any.whl (826 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.4/826.4 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (23.0)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2023.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.25.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.7.1 pytorch-lightning-1.9.3 torchmetrics-0.11.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pytorch-lightning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7vaBQx2flMa"
      },
      "source": [
        "The exclamation point (aka *bang*) at the beginning of the line instructs the system to interpret the rest of the line as a Unix command (something you might type in a Unix terminal).\n",
        "\n",
        "For example\n",
        "\n",
        "```!ls```\n",
        "\n",
        "will list the contents of the current directory\n",
        "\n",
        "`pip` is the **p**ackage **i**nstaller for **P**ython. As the name suggests, it install Python libraries (packages) that are not already present in the system. In this case,\n",
        "\n",
        "In the case above, we are installing the `pytorch-lightning` library.\n",
        "\n",
        "\n",
        "### 2. Import the computer vision library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpMG96oTflMb"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpQo-Pb6flMb"
      },
      "source": [
        "Without the bang Jupyter interprets code lines in this notebook as a Python commands which\n",
        "\n",
        "```from torchvision import models``` is.\n",
        "\n",
        "`torchvision` is a library containing models and other components for computer vision. `torch` is the basic PyTorch deep learning library.\n",
        "\n",
        "There are many pretrained models available to use. Let's take a look at the possibilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNY3j0YqflMb",
        "outputId": "547edbe4-ee40-46e1-ba27-2621bb43199a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'AlexNet_Weights',\n",
              " 'ConvNeXt',\n",
              " 'ConvNeXt_Base_Weights',\n",
              " 'ConvNeXt_Large_Weights',\n",
              " 'ConvNeXt_Small_Weights',\n",
              " 'ConvNeXt_Tiny_Weights',\n",
              " 'DenseNet',\n",
              " 'DenseNet121_Weights',\n",
              " 'DenseNet161_Weights',\n",
              " 'DenseNet169_Weights',\n",
              " 'DenseNet201_Weights',\n",
              " 'EfficientNet',\n",
              " 'EfficientNet_B0_Weights',\n",
              " 'EfficientNet_B1_Weights',\n",
              " 'EfficientNet_B2_Weights',\n",
              " 'EfficientNet_B3_Weights',\n",
              " 'EfficientNet_B4_Weights',\n",
              " 'EfficientNet_B5_Weights',\n",
              " 'EfficientNet_B6_Weights',\n",
              " 'EfficientNet_B7_Weights',\n",
              " 'EfficientNet_V2_L_Weights',\n",
              " 'EfficientNet_V2_M_Weights',\n",
              " 'EfficientNet_V2_S_Weights',\n",
              " 'GoogLeNet',\n",
              " 'GoogLeNetOutputs',\n",
              " 'GoogLeNet_Weights',\n",
              " 'Inception3',\n",
              " 'InceptionOutputs',\n",
              " 'Inception_V3_Weights',\n",
              " 'MNASNet',\n",
              " 'MNASNet0_5_Weights',\n",
              " 'MNASNet0_75_Weights',\n",
              " 'MNASNet1_0_Weights',\n",
              " 'MNASNet1_3_Weights',\n",
              " 'MaxVit',\n",
              " 'MaxVit_T_Weights',\n",
              " 'MobileNetV2',\n",
              " 'MobileNetV3',\n",
              " 'MobileNet_V2_Weights',\n",
              " 'MobileNet_V3_Large_Weights',\n",
              " 'MobileNet_V3_Small_Weights',\n",
              " 'RegNet',\n",
              " 'RegNet_X_16GF_Weights',\n",
              " 'RegNet_X_1_6GF_Weights',\n",
              " 'RegNet_X_32GF_Weights',\n",
              " 'RegNet_X_3_2GF_Weights',\n",
              " 'RegNet_X_400MF_Weights',\n",
              " 'RegNet_X_800MF_Weights',\n",
              " 'RegNet_X_8GF_Weights',\n",
              " 'RegNet_Y_128GF_Weights',\n",
              " 'RegNet_Y_16GF_Weights',\n",
              " 'RegNet_Y_1_6GF_Weights',\n",
              " 'RegNet_Y_32GF_Weights',\n",
              " 'RegNet_Y_3_2GF_Weights',\n",
              " 'RegNet_Y_400MF_Weights',\n",
              " 'RegNet_Y_800MF_Weights',\n",
              " 'RegNet_Y_8GF_Weights',\n",
              " 'ResNeXt101_32X8D_Weights',\n",
              " 'ResNeXt101_64X4D_Weights',\n",
              " 'ResNeXt50_32X4D_Weights',\n",
              " 'ResNet',\n",
              " 'ResNet101_Weights',\n",
              " 'ResNet152_Weights',\n",
              " 'ResNet18_Weights',\n",
              " 'ResNet34_Weights',\n",
              " 'ResNet50_Weights',\n",
              " 'ShuffleNetV2',\n",
              " 'ShuffleNet_V2_X0_5_Weights',\n",
              " 'ShuffleNet_V2_X1_0_Weights',\n",
              " 'ShuffleNet_V2_X1_5_Weights',\n",
              " 'ShuffleNet_V2_X2_0_Weights',\n",
              " 'SqueezeNet',\n",
              " 'SqueezeNet1_0_Weights',\n",
              " 'SqueezeNet1_1_Weights',\n",
              " 'SwinTransformer',\n",
              " 'Swin_B_Weights',\n",
              " 'Swin_S_Weights',\n",
              " 'Swin_T_Weights',\n",
              " 'Swin_V2_B_Weights',\n",
              " 'Swin_V2_S_Weights',\n",
              " 'Swin_V2_T_Weights',\n",
              " 'VGG',\n",
              " 'VGG11_BN_Weights',\n",
              " 'VGG11_Weights',\n",
              " 'VGG13_BN_Weights',\n",
              " 'VGG13_Weights',\n",
              " 'VGG16_BN_Weights',\n",
              " 'VGG16_Weights',\n",
              " 'VGG19_BN_Weights',\n",
              " 'VGG19_Weights',\n",
              " 'ViT_B_16_Weights',\n",
              " 'ViT_B_32_Weights',\n",
              " 'ViT_H_14_Weights',\n",
              " 'ViT_L_16_Weights',\n",
              " 'ViT_L_32_Weights',\n",
              " 'VisionTransformer',\n",
              " 'Wide_ResNet101_2_Weights',\n",
              " 'Wide_ResNet50_2_Weights',\n",
              " '_GoogLeNetOutputs',\n",
              " '_InceptionOutputs',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0IyX-BiflMc"
      },
      "source": [
        "That is a lot of pretrained models we can use!\n",
        "\n",
        "### 3. Load  the pretrained AlexNet model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "e852b7a635e9488dbad8a23eb8bc981c",
            "63c374dd080a4abbbee0b934ad43e995",
            "1470a11853094e3bba4aeb38540d9f80",
            "03758844653645e48b0e99de3e91b52e",
            "a03dd1aca7fc482f98e055bf7c06892f",
            "495c1cec6be14f71a412bc4468c59392",
            "5ce235992b9e4b8fa37a7bccd3ab8c70",
            "16457082c7924d5a88a3c1ecc301c07b",
            "2a771fe8532d4eacac2cf119fc3e561f",
            "052691c5ccc240babf6a309d9cdf06bd",
            "fbcc7f15d71a49469edc95f66776521f"
          ]
        },
        "id": "lxiDfvuKflMc",
        "outputId": "9f10fb25-5371-4347-aef5-2e389ca8ffd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e852b7a635e9488dbad8a23eb8bc981c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alexnet = models.alexnet(weights='AlexNet_Weights.DEFAULT')\n",
        "# have model run on the GPU\n",
        "alexnet.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu7BBAs0UoEd"
      },
      "source": [
        "And let's check to see if the model is using the GPU ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5WIqgEYUse9"
      },
      "outputs": [],
      "source": [
        "next(alexnet.parameters()).is_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yvDAoqNflMc"
      },
      "source": [
        "Excellent! CUDA is the API for NVIDIA GPUs that allow us to do parallel programming.\n",
        "\n",
        "Of course we could call this model anything we want:\n",
        "\n",
        "```\n",
        "alexnet_model = models.alexnet(pretrained=True)\n",
        "myModel = models.alexnet(pretrained=True)\n",
        "```\n",
        "\n",
        "Now we have a pretrained model loaded into our system. We would like to use the model to classify our own images. \n",
        "\n",
        "## Inference\n",
        "\n",
        "We would like to give AlexNet an image like:\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/poodle.jpg)\n",
        "\n",
        "and have AlexNet classify it. First, let's download the image file from the web using the Unix command `curl`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXZzt6a6flMc",
        "outputId": "a9ab5d3c-7888-4116-caeb-03898e63e75a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2796k  100 2796k    0     0  1285k      0  0:00:02  0:00:02 --:--:-- 1285k\n"
          ]
        }
      ],
      "source": [
        "!curl http://zacharski.org/files/courses/dmpics/poodle.jpg -o poodle.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umQSlZbRflMd"
      },
      "source": [
        "Next, let's load that image into Python using PIL (Python Imaging Library):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nI-yVPYflMd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"poodle.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OTUlDW-flMd"
      },
      "source": [
        "Now let's display that image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mny1F_BflMe"
      },
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSdD1WZQflMe"
      },
      "source": [
        "(If that doesn't display an image change the code to `img.show`)\n",
        "\n",
        "\n",
        "The size of this particular image is 4032x3024 which is slightly over 12 million pixels. That is a lot of pixels! AlexNet was designed to work with an image size of 224x224. So we need to transform the original image to AlexNet specifications by using some methods from the `torchvision` library. \n",
        "\n",
        "First we will use `transforms.Resize(256)` which transforms the image so that the smaller dimension of the original image will be resized to 256.  ([PyTorch documentation](https://pytorch.org/vision/main/generated/torchvision.transforms.Resize.html)). The resultant image will be 341x256.\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/poodleSmall.jpg)\n",
        "\n",
        "\n",
        "To get the image to the final 224x224 size we are going to use `transforms.CenterCrop(224)` which as the name suggests crops the image at the center to a 224x224 square. The result will look something like:\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/poodleCropped.jpg)\n",
        "\n",
        "\n",
        "\n",
        "Then we will convert the image to an array using `ToTensor`. Since each pixel has values for red, green and blue (RGB), the resulting array will be 224x224x3. Finally we normalize the tensor using `transforms.Normalize` ([PyTorch Documentation](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html?highlight=normalize#torchvision.transforms.Normalize)). \n",
        "\n",
        "\n",
        "\n",
        "Here are those transformations put together:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rmI2eXBflMe"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229,0.224,0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPmTNuADflMf"
      },
      "source": [
        "You may wonder where the numbers come from in \n",
        "\n",
        "```\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229,0.224,0.225])\n",
        "```\n",
        "These are the mean and standard deviation of the RGB values for all the pixels in all the images in the ImageNet dataset.\n",
        "\n",
        "Let's use this method we defined to transform the image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3I_BAn9flMf"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img)\n",
        "\n",
        "batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "# put the tensor on the GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUHn9foEflMf"
      },
      "source": [
        "Image classification models typically classify an array of images at once rather than a single image. \n",
        "\n",
        "```\n",
        "    batch_t = torch.unsqueeze(img_t, 0)\n",
        "```\n",
        "creates a tensor with one element `img_t` which itself is a tensor. In a sense, an array of image arrays.\n",
        "\n",
        "Next,\n",
        "\n",
        "```\n",
        "batch_t = batch_t.to(device)\n",
        "```\n",
        "Puts that Tensor on the GPU and\n",
        "\n",
        "```\n",
        "batch_t.is_cuda\n",
        "```\n",
        "checks to make sure that that is the case.\n",
        "\n",
        "Now we have prepared the image and are prepared to pass it to alexnet for inference.\n",
        "\n",
        "### Model Inference\n",
        "\n",
        "In PyTorch, models can be in two modes and we can toggle between them.\n",
        "\n",
        "* `alexnet.eval()` puts the model in inference mode so it can make predictions.\n",
        "* `alexnet.train()` puts the model in training mode.\n",
        "\n",
        "\n",
        "Let's get the model ready for inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07sjKJ6CflMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "263abb42-d276-49c8-dbb3-39bb3230d112"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7b038e220ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malexnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'alexnet' is not defined"
          ]
        }
      ],
      "source": [
        "alexnet.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H22BjQSlflMg"
      },
      "source": [
        "As you can see, `alexnet.eval()` displays a lot of information about the architecture of the model. We will learn about the architecture of deep learning models about midway through the course.\n",
        "\n",
        "Now let's pass the tensor of our image to alexnet and get the output. Plus, let's examine the shape of the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksUu8iE1flMg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "35c4215f-49e0-433f-b461-e9760eaefd00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-dd7241677c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'alexnet' is not defined"
          ]
        }
      ],
      "source": [
        "out = alexnet(batch_t)\n",
        "print(out.shape)\n",
        "torch.Size((1, 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WSfV73flMg"
      },
      "source": [
        "As we see `out` is a one dimensional tensor with 1,000 different values. We get 1,000 values because Image_net contained 1,000 labels for the images. The larger the number the more likely the image is of that class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itIaAMZEflMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "5705b670-4266-4f7f-ac08-9ca1655b5055"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9bc27bdc8279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiH6cKiaflMh"
      },
      "source": [
        "Let's convert those values to probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UORMvTUflMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3ed33456-b3df-482a-ca1d-84e27a74fe34"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9d58e0b6aa41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP-kvbkmflMh"
      },
      "source": [
        "As you can see, the image is not very likely to be one of the first 5 labels. What are the actual names of these labels. First let's download the label name file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmDUeY4kflMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a3d190-41a6-4770-960e-53a925641d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10472  100 10472    0     0  20294      0 --:--:-- --:--:-- --:--:-- 20294\n"
          ]
        }
      ],
      "source": [
        "!curl http://zacharski.org/files/courses/dmpics/imagenet_classes.txt -o imagenet_classes.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjlBPVW9flMi"
      },
      "source": [
        "Let's load in those labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toeNd63OflMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f5154d-6730-4770-b99c-dd243c7c4e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead']\n"
          ]
        }
      ],
      "source": [
        "with open('imagenet_classes.txt') as f:\n",
        "\n",
        "  labels = [line.strip() for line in f.readlines()]\n",
        "print(labels[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hee-TGdYflMi"
      },
      "source": [
        "The first five labels are of types of fish. It is good to know our model didn't think our image was of a fish. What does our model think?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLzeK4WIflMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "88fd23e7-047d-471f-a2d0-cda0abd24d69"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-11ab36aae0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "z_, index = torch.max(out, 1)\n",
        "print(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPw0CvPflMj"
      },
      "source": [
        "Okay, the label at index 267 is the most likely. Let's print that out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMDZWOmEflMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6418d308-2853-4f5a-cb13-9e6ef40c9329"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9d3dfcea2b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
          ]
        }
      ],
      "source": [
        "print(labels[index[0]], percentage[index[0]].item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHH57CliflMj"
      },
      "source": [
        "Fortunately, alexnet correctly thinks the image is of a standard poodle with 38.65% likelihood. \n",
        "\n",
        "The ImageNet competition evaluated systems based on the top-5 error rate meaning the system was judged correct if the correct label was among the top 5 the system predicted.  Let's look at the top 5 our model predicted for this image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL-_AsjXflMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "77291586-0323-4500-c8a5-c896337de8fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a6723ccb3dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "_, indices = torch.sort(out, descending=True)\n",
        "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dEP9tLjflMk"
      },
      "source": [
        "Let's turn what we learned into a function and try predicting the class of other images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3BT8abIflMk"
      },
      "outputs": [],
      "source": [
        "import  requests\n",
        "\n",
        "def predict(url):\n",
        "    # first download the image from the web\n",
        "    r = requests.get(url)\n",
        "    with open('tmp.jpg', 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    img = Image.open('tmp.jpg')\n",
        "    img.show()\n",
        "    img_t = transform(img)\n",
        "    batch_t = torch.unsqueeze(img_t, 0)\n",
        "    batch_t = batch_t.to(device)\n",
        "    out = alexnet(batch_t)\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    return([(labels[idx], percentage[idx].item()) for idx in indices[0][:5]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbXBwIfxflMk"
      },
      "source": [
        "Let's find out what the 1,000 labels are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCsSr4vjflMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3933286f-8b1e-4908-861b-69d11d7316fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tench                    goldfish                 great white shark        tiger shark              \n",
            "hammerhead               electric ray             stingray                 cock                     \n",
            "hen                      ostrich                  brambling                goldfinch                \n",
            "house finch              junco                    indigo bunting           robin                    \n",
            "bulbul                   jay                      magpie                   chickadee                \n",
            "water ouzel              kite                     bald eagle               vulture                  \n",
            "great grey owl           European fire salamander common newt              eft                      \n",
            "spotted salamander       axolotl                  bullfrog                 tree frog                \n",
            "tailed frog              loggerhead               leatherback turtle       mud turtle               \n",
            "terrapin                 box turtle               banded gecko             common iguana            \n",
            "American chameleon       whiptail                 agama                    frilled lizard           \n",
            "alligator lizard         Gila monster             green lizard             African chameleon        \n",
            "Komodo dragon            African crocodile        American alligator       triceratops              \n",
            "thunder snake            ringneck snake           hognose snake            green snake              \n",
            "king snake               garter snake             water snake              vine snake               \n",
            "night snake              boa constrictor          rock python              Indian cobra             \n",
            "green mamba              sea snake                horned viper             diamondback              \n",
            "sidewinder               trilobite                harvestman               scorpion                 \n",
            "black and gold garden spiderbarn spider              garden spider            black widow              \n",
            "tarantula                wolf spider              tick                     centipede                \n",
            "black grouse             ptarmigan                ruffed grouse            prairie chicken          \n",
            "peacock                  quail                    partridge                African grey             \n",
            "macaw                    sulphur-crested cockatoo lorikeet                 coucal                   \n",
            "bee eater                hornbill                 hummingbird              jacamar                  \n",
            "toucan                   drake                    red-breasted merganser   goose                    \n",
            "black swan               tusker                   echidna                  platypus                 \n",
            "wallaby                  koala                    wombat                   jellyfish                \n",
            "sea anemone              brain coral              flatworm                 nematode                 \n",
            "conch                    snail                    slug                     sea slug                 \n",
            "chiton                   chambered nautilus       Dungeness crab           rock crab                \n",
            "fiddler crab             king crab                American lobster         spiny lobster            \n",
            "crayfish                 hermit crab              isopod                   white stork              \n",
            "black stork              spoonbill                flamingo                 little blue heron        \n",
            "American egret           bittern                  crane                    limpkin                  \n",
            "European gallinule       American coot            bustard                  ruddy turnstone          \n",
            "red-backed sandpiper     redshank                 dowitcher                oystercatcher            \n",
            "pelican                  king penguin             albatross                grey whale               \n",
            "killer whale             dugong                   sea lion                 Chihuahua                \n",
            "Japanese spaniel         Maltese dog              Pekinese                 Shih-Tzu                 \n",
            "Blenheim spaniel         papillon                 toy terrier              Rhodesian ridgeback      \n",
            "Afghan hound             basset                   beagle                   bloodhound               \n",
            "bluetick                 black-and-tan coonhound  Walker hound             English foxhound         \n",
            "redbone                  borzoi                   Irish wolfhound          Italian greyhound        \n",
            "whippet                  Ibizan hound             Norwegian elkhound       otterhound               \n",
            "Saluki                   Scottish deerhound       Weimaraner               Staffordshire bullterrier\n",
            "American Staffordshire terrierBedlington terrier       Border terrier           Kerry blue terrier       \n",
            "Irish terrier            Norfolk terrier          Norwich terrier          Yorkshire terrier        \n",
            "wire-haired fox terrier  Lakeland terrier         Sealyham terrier         Airedale                 \n",
            "cairn                    Australian terrier       Dandie Dinmont           Boston bull              \n",
            "miniature schnauzer      giant schnauzer          standard schnauzer       Scotch terrier           \n",
            "Tibetan terrier          silky terrier            soft-coated wheaten terrierWest Highland white terrier\n",
            "Lhasa                    flat-coated retriever    curly-coated retriever   golden retriever         \n",
            "Labrador retriever       Chesapeake Bay retriever German short-haired pointervizsla                   \n",
            "English setter           Irish setter             Gordon setter            Brittany spaniel         \n",
            "clumber                  English springer         Welsh springer spaniel   cocker spaniel           \n",
            "Sussex spaniel           Irish water spaniel      kuvasz                   schipperke               \n",
            "groenendael              malinois                 briard                   kelpie                   \n",
            "komondor                 Old English sheepdog     Shetland sheepdog        collie                   \n",
            "Border collie            Bouvier des Flandres     Rottweiler               German shepherd          \n",
            "Doberman                 miniature pinscher       Greater Swiss Mountain dogBernese mountain dog     \n",
            "Appenzeller              EntleBucher              boxer                    bull mastiff             \n",
            "Tibetan mastiff          French bulldog           Great Dane               Saint Bernard            \n",
            "Eskimo dog               malamute                 Siberian husky           dalmatian                \n",
            "affenpinscher            basenji                  pug                      Leonberg                 \n",
            "Newfoundland             Great Pyrenees           Samoyed                  Pomeranian               \n",
            "chow                     keeshond                 Brabancon griffon        Pembroke                 \n",
            "Cardigan                 toy poodle               miniature poodle         standard poodle          \n",
            "Mexican hairless         timber wolf              white wolf               red wolf                 \n",
            "coyote                   dingo                    dhole                    African hunting dog      \n",
            "hyena                    red fox                  kit fox                  Arctic fox               \n",
            "grey fox                 tabby                    tiger cat                Persian cat              \n",
            "Siamese cat              Egyptian cat             cougar                   lynx                     \n",
            "leopard                  snow leopard             jaguar                   lion                     \n",
            "tiger                    cheetah                  brown bear               American black bear      \n",
            "ice bear                 sloth bear               mongoose                 meerkat                  \n",
            "tiger beetle             ladybug                  ground beetle            long-horned beetle       \n",
            "leaf beetle              dung beetle              rhinoceros beetle        weevil                   \n",
            "fly                      bee                      ant                      grasshopper              \n",
            "cricket                  walking stick            cockroach                mantis                   \n",
            "cicada                   leafhopper               lacewing                 dragonfly                \n",
            "damselfly                admiral                  ringlet                  monarch                  \n",
            "cabbage butterfly        sulphur butterfly        lycaenid                 starfish                 \n",
            "sea urchin               sea cucumber             wood rabbit              hare                     \n",
            "Angora                   hamster                  porcupine                fox squirrel             \n",
            "marmot                   beaver                   guinea pig               sorrel                   \n",
            "zebra                    hog                      wild boar                warthog                  \n",
            "hippopotamus             ox                       water buffalo            bison                    \n",
            "ram                      bighorn                  ibex                     hartebeest               \n",
            "impala                   gazelle                  Arabian camel            llama                    \n",
            "weasel                   mink                     polecat                  black-footed ferret      \n",
            "otter                    skunk                    badger                   armadillo                \n",
            "three-toed sloth         orangutan                gorilla                  chimpanzee               \n",
            "gibbon                   siamang                  guenon                   patas                    \n",
            "baboon                   macaque                  langur                   colobus                  \n",
            "proboscis monkey         marmoset                 capuchin                 howler monkey            \n",
            "titi                     spider monkey            squirrel monkey          Madagascar cat           \n",
            "indri                    Indian elephant          African elephant         lesser panda             \n",
            "giant panda              barracouta               eel                      coho                     \n",
            "rock beauty              anemone fish             sturgeon                 gar                      \n",
            "lionfish                 puffer                   abacus                   abaya                    \n",
            "academic gown            accordion                acoustic guitar          aircraft carrier         \n",
            "airliner                 airship                  altar                    ambulance                \n",
            "amphibian                analog clock             apiary                   apron                    \n",
            "ashcan                   assault rifle            backpack                 bakery                   \n",
            "balance beam             balloon                  ballpoint                Band Aid                 \n",
            "banjo                    bannister                barbell                  barber chair             \n",
            "barbershop               barn                     barometer                barrel                   \n",
            "barrow                   baseball                 basketball               bassinet                 \n",
            "bassoon                  bathing cap              bath towel               bathtub                  \n",
            "beach wagon              beacon                   beaker                   bearskin                 \n",
            "beer bottle              beer glass               bell cote                bib                      \n",
            "bicycle-built-for-two    bikini                   binder                   binoculars               \n",
            "birdhouse                boathouse                bobsled                  bolo tie                 \n",
            "bonnet                   bookcase                 bookshop                 bottlecap                \n",
            "bow                      bow tie                  brass                    brassiere                \n",
            "breakwater               breastplate              broom                    bucket                   \n",
            "buckle                   bulletproof vest         bullet train             butcher shop             \n",
            "cab                      caldron                  candle                   cannon                   \n",
            "canoe                    can opener               cardigan                 car mirror               \n",
            "carousel                 carpenter's kit          carton                   car wheel                \n",
            "cash machine             cassette                 cassette player          castle                   \n",
            "catamaran                CD player                cello                    cellular telephone       \n",
            "chain                    chainlink fence          chain mail               chain saw                \n",
            "chest                    chiffonier               chime                    china cabinet            \n",
            "Christmas stocking       church                   cinema                   cleaver                  \n",
            "cliff dwelling           cloak                    clog                     cocktail shaker          \n",
            "coffee mug               coffeepot                coil                     combination lock         \n",
            "computer keyboard        confectionery            container ship           convertible              \n",
            "corkscrew                cornet                   cowboy boot              cowboy hat               \n",
            "cradle                   crane                    crash helmet             crate                    \n",
            "crib                     Crock Pot                croquet ball             crutch                   \n",
            "cuirass                  dam                      desk                     desktop computer         \n",
            "dial telephone           diaper                   digital clock            digital watch            \n",
            "dining table             dishrag                  dishwasher               disk brake               \n",
            "dock                     dogsled                  dome                     doormat                  \n",
            "drilling platform        drum                     drumstick                dumbbell                 \n",
            "Dutch oven               electric fan             electric guitar          electric locomotive      \n",
            "entertainment center     envelope                 espresso maker           face powder              \n",
            "feather boa              file                     fireboat                 fire engine              \n",
            "fire screen              flagpole                 flute                    folding chair            \n",
            "football helmet          forklift                 fountain                 fountain pen             \n",
            "four-poster              freight car              French horn              frying pan               \n",
            "fur coat                 garbage truck            gasmask                  gas pump                 \n",
            "goblet                   go-kart                  golf ball                golfcart                 \n",
            "gondola                  gong                     gown                     grand piano              \n",
            "greenhouse               grille                   grocery store            guillotine               \n",
            "hair slide               hair spray               half track               hammer                   \n",
            "hamper                   hand blower              hand-held computer       handkerchief             \n",
            "hard disc                harmonica                harp                     harvester                \n",
            "hatchet                  holster                  home theater             honeycomb                \n",
            "hook                     hoopskirt                horizontal bar           horse cart               \n",
            "hourglass                iPod                     iron                     jack-o'-lantern          \n",
            "jean                     jeep                     jersey                   jigsaw puzzle            \n",
            "jinrikisha               joystick                 kimono                   knee pad                 \n",
            "knot                     lab coat                 ladle                    lampshade                \n",
            "laptop                   lawn mower               lens cap                 letter opener            \n",
            "library                  lifeboat                 lighter                  limousine                \n",
            "liner                    lipstick                 Loafer                   lotion                   \n",
            "loudspeaker              loupe                    lumbermill               magnetic compass         \n",
            "mailbag                  mailbox                  maillot                  maillot                  \n",
            "manhole cover            maraca                   marimba                  mask                     \n",
            "matchstick               maypole                  maze                     measuring cup            \n",
            "medicine chest           megalith                 microphone               microwave                \n",
            "military uniform         milk can                 minibus                  miniskirt                \n",
            "minivan                  missile                  mitten                   mixing bowl              \n",
            "mobile home              Model T                  modem                    monastery                \n",
            "monitor                  moped                    mortar                   mortarboard              \n",
            "mosque                   mosquito net             motor scooter            mountain bike            \n",
            "mountain tent            mouse                    mousetrap                moving van               \n",
            "muzzle                   nail                     neck brace               necklace                 \n",
            "nipple                   notebook                 obelisk                  oboe                     \n",
            "ocarina                  odometer                 oil filter               organ                    \n",
            "oscilloscope             overskirt                oxcart                   oxygen mask              \n",
            "packet                   paddle                   paddlewheel              padlock                  \n",
            "paintbrush               pajama                   palace                   panpipe                  \n",
            "paper towel              parachute                parallel bars            park bench               \n",
            "parking meter            passenger car            patio                    pay-phone                \n",
            "pedestal                 pencil box               pencil sharpener         perfume                  \n",
            "Petri dish               photocopier              pick                     pickelhaube              \n",
            "picket fence             pickup                   pier                     piggy bank               \n",
            "pill bottle              pillow                   ping-pong ball           pinwheel                 \n",
            "pirate                   pitcher                  plane                    planetarium              \n",
            "plastic bag              plate rack               plow                     plunger                  \n",
            "Polaroid camera          pole                     police van               poncho                   \n",
            "pool table               pop bottle               pot                      potter's wheel           \n",
            "power drill              prayer rug               printer                  prison                   \n",
            "projectile               projector                puck                     punching bag             \n",
            "purse                    quill                    quilt                    racer                    \n",
            "racket                   radiator                 radio                    radio telescope          \n",
            "rain barrel              recreational vehicle     reel                     reflex camera            \n",
            "refrigerator             remote control           restaurant               revolver                 \n",
            "rifle                    rocking chair            rotisserie               rubber eraser            \n",
            "rugby ball               rule                     running shoe             safe                     \n",
            "safety pin               saltshaker               sandal                   sarong                   \n",
            "sax                      scabbard                 scale                    school bus               \n",
            "schooner                 scoreboard               screen                   screw                    \n",
            "screwdriver              seat belt                sewing machine           shield                   \n",
            "shoe shop                shoji                    shopping basket          shopping cart            \n",
            "shovel                   shower cap               shower curtain           ski                      \n",
            "ski mask                 sleeping bag             slide rule               sliding door             \n",
            "slot                     snorkel                  snowmobile               snowplow                 \n",
            "soap dispenser           soccer ball              sock                     solar dish               \n",
            "sombrero                 soup bowl                space bar                space heater             \n",
            "space shuttle            spatula                  speedboat                spider web               \n",
            "spindle                  sports car               spotlight                stage                    \n",
            "steam locomotive         steel arch bridge        steel drum               stethoscope              \n",
            "stole                    stone wall               stopwatch                stove                    \n",
            "strainer                 streetcar                stretcher                studio couch             \n",
            "stupa                    submarine                suit                     sundial                  \n",
            "sunglass                 sunglasses               sunscreen                suspension bridge        \n",
            "swab                     sweatshirt               swimming trunks          swing                    \n",
            "switch                   syringe                  table lamp               tank                     \n",
            "tape player              teapot                   teddy                    television               \n",
            "tennis ball              thatch                   theater curtain          thimble                  \n",
            "thresher                 throne                   tile roof                toaster                  \n",
            "tobacco shop             toilet seat              torch                    totem pole               \n",
            "tow truck                toyshop                  tractor                  trailer truck            \n",
            "tray                     trench coat              tricycle                 trimaran                 \n",
            "tripod                   triumphal arch           trolleybus               trombone                 \n",
            "tub                      turnstile                typewriter keyboard      umbrella                 \n",
            "unicycle                 upright                  vacuum                   vase                     \n",
            "vault                    velvet                   vending machine          vestment                 \n",
            "viaduct                  violin                   volleyball               waffle iron              \n",
            "wall clock               wallet                   wardrobe                 warplane                 \n",
            "washbasin                washer                   water bottle             water jug                \n",
            "water tower              whiskey jug              whistle                  wig                      \n",
            "window screen            window shade             Windsor tie              wine bottle              \n",
            "wing                     wok                      wooden spoon             wool                     \n",
            "worm fence               wreck                    yawl                     yurt                     \n",
            "web site                 comic book               crossword puzzle         street sign              \n",
            "traffic light            book jacket              menu                     plate                    \n",
            "guacamole                consomme                 hot pot                  trifle                   \n",
            "ice cream                ice lolly                French loaf              bagel                    \n",
            "pretzel                  cheeseburger             hotdog                   mashed potato            \n",
            "head cabbage             broccoli                 cauliflower              zucchini                 \n",
            "spaghetti squash         acorn squash             butternut squash         cucumber                 \n",
            "artichoke                bell pepper              cardoon                  mushroom                 \n",
            "Granny Smith             strawberry               orange                   lemon                    \n",
            "fig                      pineapple                banana                   jackfruit                \n",
            "custard apple            pomegranate              hay                      carbonara                \n",
            "chocolate sauce          dough                    meat loaf                pizza                    \n",
            "potpie                   burrito                  red wine                 espresso                 \n",
            "cup                      eggnog                   alp                      bubble                   \n",
            "cliff                    coral reef               geyser                   lakeside                 \n",
            "promontory               sandbar                  seashore                 valley                   \n",
            "volcano                  ballplayer               groom                    scuba diver              \n",
            "rapeseed                 daisy                    yellow lady's slipper    corn                     \n",
            "acorn                    hip                      buckeye                  coral fungus             \n",
            "agaric                   gyromitra                stinkhorn                earthstar                \n",
            "hen-of-the-woods         bolete                   ear                      toilet tissue            \n"
          ]
        }
      ],
      "source": [
        "\n",
        "line = ''\n",
        "for i in range(len(labels)):\n",
        "  line += '%-25s' %labels[i]\n",
        "  if (i + 1) % 4 == 0:\n",
        "    print(line)\n",
        "    line = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYkTXbujflMl"
      },
      "source": [
        "Electric Guitar is one of the labels. Let's see if our model correctly identifies a picture of one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUjOor_oflMl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "31f79bf3-8393-46b8-a182-c6badae6887b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5aecaaf087d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/Fender_Stratocaster.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ],
      "source": [
        "predict('https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/Fender_Stratocaster.jpeg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8msErztflMl"
      },
      "source": [
        "Our system is 99% sure that this image is an electric guitar.\n",
        "\n",
        "While AlexNet doesn't know about burrowing owls it does know about great horned owls. Let's give it a picture of a burrowing owl and see what it does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUMAPhl-flMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "386ed74d-9f6b-42fb-c99e-a35e9a445081"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7a28a516e4bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/greyOwl.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-efd9422eed3c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "predict('https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/greyOwl.jpeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkazE55flMm"
      },
      "source": [
        "That is a reasonable response!\n",
        "\n",
        "Let's try a cello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bKIiLdNflMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "881126f1-a283-42b8-b610-69a17cd786ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f451e1f86a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/cello12.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-efd9422eed3c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "predict('https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/cello12.jpeg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCLaql64flMm"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/torchdivide.png)\n",
        "\n",
        "\n",
        "# <font color='#EE4C2C'>You Try ...</font> \n",
        "Ok, it is time for you to try out what you just learned.\n",
        "\n",
        "## <font color='#EE4C2C'>1. Your own images</font> \n",
        "Try this out on three images of your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GanSdKhSflMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "468ac5b7-8537-4254-96de-7ffe9db23991"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8054d1d666fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file:///Users/yadisabelliard/Downloads/Golden%20Retriever%20Puppy%20Wallpapers%20-%20Top%20Free%20Golden%20Retriever%20Puppy%20Backgrounds%20-%20WallpaperAccess_files/883519.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ],
      "source": [
        "predict('file:///Users/yadisabelliard/Downloads/Golden%20Retriever%20Puppy%20Wallpapers%20-%20Top%20Free%20Golden%20Retriever%20Puppy%20Backgrounds%20-%20WallpaperAccess_files/883519.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoHaOAiZflMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "f0d0be8a-f502-407f-cef7-525899679261"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-14dfcbdfc59e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https:/encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQHGOAA217qYM_WMcPJ-HYtaMsMswbZ3sHTvFPSZHVTbsQdawgzs8_iXQMMYAsVYVoVz9E&usqp=CAU\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "https:/encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQHGOAA217qYM_WMcPJ-HYtaMsMswbZ3sHTvFPSZHVTbsQdawgzs8_iXQMMYAsVYVoVz9E&usqp=CAU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhck8yneflMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "df1017d9-39e5-4b2c-c4b2-f7c61e0a893b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-b948c1470b1b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSwK8dm-Yz8SS2TyOxg-SL2Ahmpo7L54goUfDCDHkZT-L-r-3Yv-48uFszzpi9nFGDUsFE&usqp=CAU\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSwK8dm-Yz8SS2TyOxg-SL2Ahmpo7L54goUfDCDHkZT-L-r-3Yv-48uFszzpi9nFGDUsFE&usqp=CAU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbFQ20DUflMn"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>2. Squeezenet</font> \n",
        "\n",
        "Let's try a different pretrained model, `squeezenet1_1`. Load the model, construct a function that will make predictions based on the model and try it out on the images above that we provided plus your three.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57or8T7-flMn"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eM_-FIdflMn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wxkMyuAflMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oglJGX8flMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05iaa3rhflMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAgCjkvwflMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqdx9MG8flMo"
      },
      "source": [
        "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
        "## <font color='#EE4C2C'>2. Summary</font> \n",
        "\n",
        "Please answer the following questions by editing this markdown cell. </span>\n",
        "\n",
        "1. Classification machine learning models have two modes. What are they?  <font color='#EE4C2C'>All machine learning models are categorized as either supervised or unsupervised</font> \n",
        "2. What is a pretrained model? <font color='#EE4C2C'>\n",
        "A saved network that was trained on a large dataset, typically on a large-scale image-classification task.</font> \n",
        "2. What is supervised learning? What is unsupervised learning?<font color='#EE4C2C'>\n",
        "supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not.</font> \n",
        "\n",
        "3. Describe in a few sentences what Squeezenet is. (requires a bit of googling)<font color='#EE4C2C'>\n",
        "SqueezeNet is a convolutional neural network that is 18 layers deep. You can load a version of the network trained on more than a million images from the database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, and many animals. The network has learned feature representations for a wide range of images. \n",
        "</font> \n",
        "4. Compare the performance of AlexNet over Squeezenet. Was one more accurate than the other? Did you notice any other differences? <font color='#EE4C2C'>AlexNet is slightly more accurate than squeezenet. Alexnet also saves us time. It also recognizes images up to 10,000 categories.</font> \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfTcoR11424A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0aK-Aw_flMo"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03758844653645e48b0e99de3e91b52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052691c5ccc240babf6a309d9cdf06bd",
            "placeholder": "​",
            "style": "IPY_MODEL_fbcc7f15d71a49469edc95f66776521f",
            "value": " 233M/233M [00:00&lt;00:00, 271MB/s]"
          }
        },
        "052691c5ccc240babf6a309d9cdf06bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1470a11853094e3bba4aeb38540d9f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16457082c7924d5a88a3c1ecc301c07b",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a771fe8532d4eacac2cf119fc3e561f",
            "value": 244408911
          }
        },
        "16457082c7924d5a88a3c1ecc301c07b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a771fe8532d4eacac2cf119fc3e561f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "495c1cec6be14f71a412bc4468c59392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce235992b9e4b8fa37a7bccd3ab8c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c374dd080a4abbbee0b934ad43e995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495c1cec6be14f71a412bc4468c59392",
            "placeholder": "​",
            "style": "IPY_MODEL_5ce235992b9e4b8fa37a7bccd3ab8c70",
            "value": "100%"
          }
        },
        "a03dd1aca7fc482f98e055bf7c06892f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e852b7a635e9488dbad8a23eb8bc981c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63c374dd080a4abbbee0b934ad43e995",
              "IPY_MODEL_1470a11853094e3bba4aeb38540d9f80",
              "IPY_MODEL_03758844653645e48b0e99de3e91b52e"
            ],
            "layout": "IPY_MODEL_a03dd1aca7fc482f98e055bf7c06892f"
          }
        },
        "fbcc7f15d71a49469edc95f66776521f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}